#log_folder: 'log_quick'

# Used to quickly test a model or dataset. Simply uncomment the model or dataset you want to run. (last uncommented model/dataset is used)
# model: gcn
#model: gat
#model: seal
#model: egcn_h
# model: gclstm
model: gc_transformer
#model: tgat
#model: tgn
#model: random #Called R-embed from paper
#model: random_heuristic # Called random in paper
#model: cn
#model: aa
#model: jaccard 
#model: newton
# model: ccpa

data: enron
#data: uc
#data: bitcoin-otc
#data: autonomous-systems
#data: wikipedia
#data: reddit

#one_cell: True
use_cuda: True
use_logfile: False #True/False
notify: False
skip_computed_grid_cells: False
run_downstream: False
force_encode: True

#Heuristics
include_existing_edges: False #'adaptive' #False

negative_mult_training: 1
random_feats: True
learning_rate: 
    - 0.0001
decoder_learning_rate:
    - 0.01
decoder_weight_decay:
    - 0.01
num_epochs: 100
num_epochs_continuous: 10
eval_after_epochs: 5
num_hist_steps: 5 #'expanding' #'static' #1 #10 #'static' # number of previous steps used for prediction

seed: 1235
data_loading_params:
  batch_size: 1
  num_workers: 1

gcn_parameters:
  # GAT, TGAT and TGN
  attention_heads: 2
  dropout: 0.1
  # TGN
  use_memory: True

  # EGCN
  k_top_grcu: 200

  # GC-LSTM
  K: 3

  # transformer
  d_model: 32
  num_layers: 6
  


  # All
  layer_1_feats: 10
  layer_2_feats_same_as_l1: True
  num_layers: 2 #Often doesn't do anything, most models have 2 layers hard coded
  cls_feats: 10
