data: enron
model: tgat

continuous_batch_size:
  - 200 

random_feats:
  - True

learning_rate:
  - 0.001
decoder_weight_decay:
  - 0.01
decoder_learning_rate:
  - 0.05

num_hist_steps: 1 

gcn_parameters:
  attention_heads: 2
  dropout: 0.1
  layer_1_feats: 10
  layer_2_feats_same_as_l1: True
  num_layers: 2
  cls_feats: 10 
